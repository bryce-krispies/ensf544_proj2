{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementation of Naive Bayes Algorithm found in the paper Beyond Accuracy: ROI-driven Data Analytics of Empirical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "JjLSWM6G6k6c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Import the data from 2 files (My computer runs out of memory with more)\n",
        "\n",
        "#alldata = pd.read_csv('./dataset/AllData.csv', low_memory=False)\n",
        "data_part1 = pd.read_csv('./dataset/Data_part1.csv', low_memory=False) #Only this dataset was used to calculate results, but more can easily be added\n",
        "#data_part1Stage2 = pd.read_csv('./dataset/Data_part1Stage2.csv', low_memory=False)\n",
        "#data_part2 = pd.read_csv('./dataset/Data_part2.csv', low_memory=False)\n",
        "#data_part2Stage2 = pd.read_csv('./dataset/Data_part2Stage2.csv', low_memory=False)\n",
        "#data_part3 = pd.read_csv('./dataset/Data_part3.csv', low_memory=False)\n",
        "#data_part3Stage2 = pd.read_csv('./dataset/Data_part3Stage2.csv', low_memory=False)\n",
        "#data_part4 = pd.read_csv('./dataset/Data_part4.csv', low_memory=False)\n",
        "#data_part4Stage2 = pd.read_csv('./dataset/Data_part4Stage2.csv', low_memory=False)\n",
        "#data_part5Stage2 = pd.read_csv('./dataset/Data_part5Stage2.csv', low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "VW1EvSBY6k6k"
      },
      "outputs": [],
      "source": [
        "dataset_names = [data_part1] #[data_part1, data_part1Stage2] #Add more dataset names to this list to create larger dataset\n",
        "complete_dataset =  pd.concat(dataset_names, ignore_index=True, sort=False).drop(columns=['Unnamed: 0']) #Put the files into one dataframe\n",
        "complete_dataset = complete_dataset.drop(columns=list(complete_dataset.filter(regex = '^cf'))) #Remove all columns with cf\n",
        "complete_dataset = complete_dataset.set_index('id') #Create an explicit index. Each row can now be refered to by it's ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ha7h1Uo6k6m",
        "outputId": "667d8378-aa90-4578-8f18-1325c0306b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1130266', '1448703', '1529362', '1319773', '1231208', '1445197', '1575284', '1574241', '1460343', '1470432', '1471622', '1464426', '1444991', '1218018', '1478118', '1477783', '278458', '1217996', '1344091', '1441308', '1467949', '1353360', '1172897', '1476876', '1480504', '1457891', '910412', '1418995', '1472491', '1477638', '1212797', '1461360', '57805', '231429', '1462470', '1490242', '947490', '1449562', '1464828', '1574159', '426727', '1427928', '1350424', '252848', '1492566', '1354083', '1320475', '1476865', '912121', '1456555', '1191460', '790640', '1234485', '1356397', '1196785', '1073717', '1082598', '1436478', '1494403', '1472491', '1270763', '403137', '1467221', '1446830', '1464311', '1466549', '851471', '38447', '1247628', '899013', '903519', '1485081', '1250473', '1334655', '1475252', '1473530', '1250902', '1473772', '1342026', '1464123', '1488620', '1463587', '106592', '1457891', '1457500', '18729', '1357819', '1317102', '1452845', '1425941', '1425484', '1364359', '1272256', '1319493', '1496671', '1408053', '1423623', '1062849', '1455422', '1059325']\n"
          ]
        }
      ],
      "source": [
        "#Get all of the rows which depend on something\n",
        "index_dataset = complete_dataset[['depends_on']]\n",
        "index_dataset = index_dataset.dropna()\n",
        "\n",
        "#If you have multiple values in one cell, split them into different columns (Ex: 2 items seperated by a comma = 2 columns)\n",
        "targets = index_dataset['depends_on'].str.split(',', expand=True)\n",
        "#Count the number of instances in each row\n",
        "result = targets.apply(pd.Series.value_counts)\n",
        "#Remove NaN values - they throw things off\n",
        "result = result.fillna(0)\n",
        "\n",
        "#Sum all the columns, based on row. This will give us the total count for how many entries \n",
        "#are dependent on another, with the index being the ID of the \"depends_on\" entry\n",
        "result = result.sum(axis='columns').to_frame()\n",
        "\n",
        "#Find the entries which have the most references in the \"depends_on\" column\n",
        "result = result.sort_values(by = 0, ascending=False)\n",
        "\n",
        "#Get the top 80 referenced entries\n",
        "result = result.head(100)\n",
        "\n",
        "#Make a list of the entries\n",
        "indicies = result.index.values.tolist()\n",
        "\n",
        "#Make sure the entries are in string format, with all whitespace stripped\n",
        "indicies = list(map(str,indicies))\n",
        "indicies = [i.strip() for i in indicies]\n",
        "print(indicies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "Of0YfG7c6k6n",
        "outputId": "6e8aaeb4-8263-4d2a-9c7f-80433f2b51c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/catcyr/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/catcyr/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /Users/catcyr/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9879, 2)\n"
          ]
        }
      ],
      "source": [
        "#Import the library which has the stopwords (if, the, etc...)\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "#Give me the depends_on and summary column\n",
        "complete_dataset = complete_dataset[['depends_on', 'summary']]\n",
        "print(complete_dataset.shape) #Check how big the dataframe is\n",
        "\n",
        "#Used to remove the stopwords\n",
        "def removeStopWords(startingList):\n",
        "    returnedList = [x for x in startingList if x not in stopwords.words('english')]\n",
        "    return returnedList\n",
        "\n",
        "def lemmatize(startingList):\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    returnedList = [lmtzr.lemmatize(x) for x in startingList]\n",
        "    return returnedList\n",
        "\n",
        "#Used to remove punctuation from the summary column\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "#Get the summary column\n",
        "summary_features = complete_dataset['summary']\n",
        "summary_features = summary_features.to_frame()\n",
        "\n",
        "#Remove punctuation\n",
        "summary_features = summary_features.apply(lambda x: tokenizer.tokenize(x['summary']), axis=1)\n",
        "#Remove stopwords\n",
        "summary_features = summary_features.apply(lambda x: removeStopWords(x))\n",
        "#Lemmatize\n",
        "summary_features = summary_features.apply(lambda x: lemmatize(x))\n",
        "\n",
        "#Get the \"depends_on\" column into its own dataframe, change each cell to hold a list of strings (each ID = 1 string) instead of one string\n",
        "targets = complete_dataset['depends_on'].str.split(',').to_frame()\n",
        "#Replace all NaN values with empty lists\n",
        "targets['depends_on'] = targets['depends_on'].apply(lambda x: x if isinstance(x, list) else [])\n",
        "summary_features = summary_features.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "WJdx3s0a6k6p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         1000077  1000199  1000317  1000462  1000745  1000775  1000814  \\\n",
            "id                                                                       \n",
            "1572867        0        0        0        0        0        0        0   \n",
            "1572870        0        0        0        0        0        0        0   \n",
            "1572872        0        0        0        0        0        0        0   \n",
            "1441804        0        0        0        0        0        0        0   \n",
            "1048589        0        0        0        0        0        0        0   \n",
            "...          ...      ...      ...      ...      ...      ...      ...   \n",
            "1486848        0        0        0        0        0        0        0   \n",
            "1355787        0        0        0        0        0        0        0   \n",
            "1486859        0        0        0        0        0        0        0   \n",
            "1486865        0        0        0        0        0        0        0   \n",
            "1486866        0        0        0        0        0        0        0   \n",
            "\n",
            "         1000870  1000879  100090  ...  992569  9942  995252  996174  997190  \\\n",
            "id                                 ...                                         \n",
            "1572867        0        0       0  ...       0     0       0       0       0   \n",
            "1572870        0        0       0  ...       0     0       0       0       0   \n",
            "1572872        0        0       0  ...       0     0       0       0       0   \n",
            "1441804        0        0       0  ...       0     0       0       0       0   \n",
            "1048589        0        0       0  ...       0     0       0       0       0   \n",
            "...          ...      ...     ...  ...     ...   ...     ...     ...     ...   \n",
            "1486848        0        0       0  ...       0     0       0       0       0   \n",
            "1355787        0        0       0  ...       0     0       0       0       0   \n",
            "1486859        0        0       0  ...       0     0       0       0       0   \n",
            "1486865        0        0       0  ...       0     0       0       0       0   \n",
            "1486866        0        0       0  ...       0     0       0       0       0   \n",
            "\n",
            "         997779  997906  998343  998494  999754  \n",
            "id                                               \n",
            "1572867       0       0       0       0       0  \n",
            "1572870       0       0       0       0       0  \n",
            "1572872       0       0       0       0       0  \n",
            "1441804       0       0       0       0       0  \n",
            "1048589       0       0       0       0       0  \n",
            "...         ...     ...     ...     ...     ...  \n",
            "1486848       0       0       0       0       0  \n",
            "1355787       0       0       0       0       0  \n",
            "1486859       0       0       0       0       0  \n",
            "1486865       0       0       0       0       0  \n",
            "1486866       0       0       0       0       0  \n",
            "\n",
            "[9879 rows x 27383 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "#Change the summary dataframe to onehot encoding - each row can have more than one \"1\" because sentence have multiple words\n",
        "mlb = MultiLabelBinarizer()\n",
        "features = summary_features.join(pd.DataFrame(mlb.fit_transform(summary_features.pop(0)), columns=mlb.classes_, index=summary_features.index))\n",
        "original_features = features\n",
        "\n",
        "#Change the depends_on dataframe to onehot encoding\n",
        "targets = targets.join(pd.DataFrame(mlb.fit_transform(targets.pop('depends_on')), columns=mlb.classes_, index=targets.index))\n",
        "\n",
        "#Remove whitespaces in the column names\n",
        "targets.columns = targets.columns.str.strip()\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "n9jKDyOO6k6q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id\n",
            "915        0\n",
            "2654       0\n",
            "2678       0\n",
            "2800       0\n",
            "2892       0\n",
            "          ..\n",
            "1575563    0\n",
            "1575565    0\n",
            "1575567    0\n",
            "1575575    0\n",
            "1575582    0\n",
            "Length: 9879, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Select only the  top  80 dependencies\n",
        "targets2 = targets[indicies]\n",
        "#Remove duplicate rows and columns\n",
        "targets2 = targets2.groupby(level=0, axis=1).sum()\n",
        "targets2 = targets2.groupby(level=0, axis=0).sum()\n",
        "\n",
        "#Create a single column of rows that have dependencies in the top 80 and those which do not\n",
        "targets2 = targets2.max(axis = 1)\n",
        "print(targets2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9451\n",
            "411\n",
            "id\n",
            "2800       0\n",
            "5704       0\n",
            "11056      1\n",
            "19251      0\n",
            "32023      0\n",
            "          ..\n",
            "1575279    1\n",
            "1575280    1\n",
            "1575281    1\n",
            "1575282    1\n",
            "1575283    1\n",
            "Length: 822, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Reduce the overall number of entires\n",
        "#Select all entries that are equal to 1 (has a dependency) and 0 (does not have a dependency)\n",
        "zeroes = targets2[targets2 == 0]\n",
        "ones = targets2[targets2 == 1]\n",
        "print(len(zeroes))\n",
        "print(len(ones))\n",
        "\n",
        "#Sample list of zeroes and select the same as the number of dependency entries\n",
        "zeroes_sampled = zeroes.sample(n = len(ones))\n",
        "\n",
        "#combine lists and sort by index\n",
        "zeroes_ones = pd.concat([zeroes_sampled, ones])\n",
        "zeroes_ones = zeroes_ones.sort_index(ascending = True)\n",
        "\n",
        "targets2 = zeroes_ones\n",
        "\n",
        "print(zeroes_ones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "9GbD77cq6k6q"
      },
      "outputs": [],
      "source": [
        "#Get the indecies of the selected target values\n",
        "target_indicies = targets2.index.values.tolist()\n",
        "\n",
        "#Remove duplicate rows\n",
        "features = features.groupby(level=0, axis=0).sum()\n",
        "#Select features which match the target indicies\n",
        "features = features.loc[target_indicies]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "tG8HARlk6k6r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[43 10]\n",
            " [20 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.68      0.81      0.74        53\n",
            "   Dependent       0.50      0.33      0.40        30\n",
            "\n",
            "    accuracy                           0.64        83\n",
            "   macro avg       0.59      0.57      0.57        83\n",
            "weighted avg       0.62      0.64      0.62        83\n",
            "\n",
            "[[46  9]\n",
            " [18 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.72      0.84      0.77        55\n",
            "   Dependent       0.53      0.36      0.43        28\n",
            "\n",
            "    accuracy                           0.67        83\n",
            "   macro avg       0.62      0.60      0.60        83\n",
            "weighted avg       0.65      0.67      0.66        83\n",
            "\n",
            "[[35  8]\n",
            " [22 17]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.61      0.81      0.70        43\n",
            "   Dependent       0.68      0.44      0.53        39\n",
            "\n",
            "    accuracy                           0.63        82\n",
            "   macro avg       0.65      0.62      0.62        82\n",
            "weighted avg       0.65      0.63      0.62        82\n",
            "\n",
            "[[33  5]\n",
            " [22 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.60      0.87      0.71        38\n",
            "   Dependent       0.81      0.50      0.62        44\n",
            "\n",
            "    accuracy                           0.67        82\n",
            "   macro avg       0.71      0.68      0.66        82\n",
            "weighted avg       0.72      0.67      0.66        82\n",
            "\n",
            "[[33  4]\n",
            " [21 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.61      0.89      0.73        37\n",
            "   Dependent       0.86      0.53      0.66        45\n",
            "\n",
            "    accuracy                           0.70        82\n",
            "   macro avg       0.73      0.71      0.69        82\n",
            "weighted avg       0.75      0.70      0.69        82\n",
            "\n",
            "[[35  8]\n",
            " [19 20]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.65      0.81      0.72        43\n",
            "   Dependent       0.71      0.51      0.60        39\n",
            "\n",
            "    accuracy                           0.67        82\n",
            "   macro avg       0.68      0.66      0.66        82\n",
            "weighted avg       0.68      0.67      0.66        82\n",
            "\n",
            "[[20  2]\n",
            " [30 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.40      0.91      0.56        22\n",
            "   Dependent       0.94      0.50      0.65        60\n",
            "\n",
            "    accuracy                           0.61        82\n",
            "   macro avg       0.67      0.70      0.60        82\n",
            "weighted avg       0.79      0.61      0.63        82\n",
            "\n",
            "[[27  7]\n",
            " [32 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.46      0.79      0.58        34\n",
            "   Dependent       0.70      0.33      0.45        48\n",
            "\n",
            "    accuracy                           0.52        82\n",
            "   macro avg       0.58      0.56      0.52        82\n",
            "weighted avg       0.60      0.52      0.50        82\n",
            "\n",
            "[[27  9]\n",
            " [19 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.59      0.75      0.66        36\n",
            "   Dependent       0.75      0.59      0.66        46\n",
            "\n",
            "    accuracy                           0.66        82\n",
            "   macro avg       0.67      0.67      0.66        82\n",
            "weighted avg       0.68      0.66      0.66        82\n",
            "\n",
            "[[43  7]\n",
            " [17 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.72      0.86      0.78        50\n",
            "   Dependent       0.68      0.47      0.56        32\n",
            "\n",
            "    accuracy                           0.71        82\n",
            "   macro avg       0.70      0.66      0.67        82\n",
            "weighted avg       0.70      0.71      0.69        82\n",
            "\n",
            "Mean precision score after 10-fold cross validation: 0.6828540136713592\n",
            "Mean recall score after 10-fold cross validation: 0.6483984719365266\n",
            "Mean F1 score after 10-fold cross validation: 0.638835436132333\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#10-fold cross validator\n",
        "kf = KFold(n_splits = 10)\n",
        "\n",
        "#Create an SVM classifier\n",
        "svm = SVC(kernel='rbf', C=20.0, gamma='scale')\n",
        "\n",
        "#List the results of the 10-fold CV\n",
        "f1_scores = []\n",
        "prec_scores = []\n",
        "rec_scores = []\n",
        "\n",
        "labels = targets2.to_list()\n",
        "\n",
        "for k, (train, test) in enumerate(kf.split(features, labels)):\n",
        "    #Fit the SVC classifier\n",
        "    svm.fit(features.iloc[train], targets2.iloc[train])\n",
        "    \n",
        "    #Predict y\n",
        "    y_predict = svm.predict(features.iloc[test])\n",
        "\n",
        "    #Collect scores from all splits\n",
        "    prec_scores.append(precision_score(targets2.iloc[test], y_predict, average='weighted'))\n",
        "    rec_scores.append(recall_score(targets2.iloc[test], y_predict, average='weighted'))\n",
        "    f1_scores.append(f1_score(targets2.iloc[test], y_predict, average='weighted'))\n",
        "    \n",
        "    #Print confusion matrix and classification report\n",
        "    print(confusion_matrix(targets2.iloc[test], y_predict))\n",
        "    print(classification_report(targets2.iloc[test], y_predict, target_names=[\"Independent\", \"Dependent\"]))\n",
        "    \n",
        "#Print mean scores from all splits\n",
        "print(\"Mean precision score after 10-fold cross validation: {}\".format(np.mean(prec_scores)))\n",
        "print(\"Mean recall score after 10-fold cross validation: {}\".format(np.mean(rec_scores)))\n",
        "print(\"Mean F1 score after 10-fold cross validation: {}\".format(np.mean(f1_scores)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "nb = GaussianNB()\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "nb.fit(features, targets2)\n",
        "rf.fit(features, targets2)\n",
        "\n",
        "test_targets = targets.drop(targets2.index)\n",
        "#Remove duplicate rows\n",
        "test_features = original_features.groupby(level=0, axis=0).sum()\n",
        "#Select features which match the target indicies\n",
        "test_features = test_features.loc[test_targets.index]\n",
        "\n",
        "nb_predicted = nb.predict(test_features)\n",
        "rf_predicted = rf.predict(test_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "WbU3TLbm6k6s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 0 0 0]\n",
            "[0 0 0 ... 0 1 0]\n",
            "411.0\n"
          ]
        }
      ],
      "source": [
        "print(nb_predicted)\n",
        "print(rf_predicted)\n",
        "\n",
        "matching_indices = [np.where(nb_predicted == rf_predicted)]\n",
        "nb_zeroes = [np.where(nb_predicted == 0)]\n",
        "nb_ones = [np.where(nb_predicted == 1)]\n",
        "\n",
        "matching_zeroes = [element for element in matching_indices[0][0] if element in nb_zeroes[0][0]]\n",
        "\n",
        "matching_ones = [element for element in matching_indices[0][0] if element in nb_ones[0][0]]\n",
        "\n",
        "smaller_array_size = min(len(matching_zeroes), len(matching_ones))\n",
        "samples_to_add = min(smaller_array_size, len(labels)) / 2\n",
        "print(samples_to_add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_matching_zeroes = matching_zeroes[:(int(samples_to_add) + 1)]\n",
        "new_matching_ones = matching_ones[:(int(samples_to_add) + 1)]\n",
        "new_indices = original_features.index.to_list()\n",
        "\n",
        "independent_indices = [new_indices[index] for index in new_matching_zeroes]\n",
        "dependent_indices = [new_indices[index] for index in new_matching_ones]\n",
        "\n",
        "all_new_indices = np.sort(independent_indices + dependent_indices)\n",
        "\n",
        "new_features = original_features.groupby(level=0, axis=0).sum()\n",
        "new_features = new_features.loc[all_new_indices]\n",
        "\n",
        "new_labels = []\n",
        "for index in all_new_indices:\n",
        "    if index in independent_indices:\n",
        "        new_labels.append(0)\n",
        "    else:\n",
        "        new_labels.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[44 63]\n",
            " [21 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.68      0.41      0.51       107\n",
            "   Dependent       0.37      0.64      0.47        58\n",
            "\n",
            "    accuracy                           0.49       165\n",
            "   macro avg       0.52      0.52      0.49       165\n",
            "weighted avg       0.57      0.49      0.50       165\n",
            "\n",
            "[[35 47]\n",
            " [35 48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.50      0.43      0.46        82\n",
            "   Dependent       0.51      0.58      0.54        83\n",
            "\n",
            "    accuracy                           0.50       165\n",
            "   macro avg       0.50      0.50      0.50       165\n",
            "weighted avg       0.50      0.50      0.50       165\n",
            "\n",
            "[[39 41]\n",
            " [36 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.52      0.49      0.50        80\n",
            "   Dependent       0.54      0.58      0.56        85\n",
            "\n",
            "    accuracy                           0.53       165\n",
            "   macro avg       0.53      0.53      0.53       165\n",
            "weighted avg       0.53      0.53      0.53       165\n",
            "\n",
            "[[29 27]\n",
            " [55 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.35      0.52      0.41        56\n",
            "   Dependent       0.67      0.50      0.57       109\n",
            "\n",
            "    accuracy                           0.50       165\n",
            "   macro avg       0.51      0.51      0.49       165\n",
            "weighted avg       0.56      0.50      0.52       165\n",
            "\n",
            "[[43 45]\n",
            " [38 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.53      0.49      0.51        88\n",
            "   Dependent       0.46      0.51      0.48        77\n",
            "\n",
            "    accuracy                           0.50       165\n",
            "   macro avg       0.50      0.50      0.50       165\n",
            "weighted avg       0.50      0.50      0.50       165\n",
            "\n",
            "[[33 30]\n",
            " [54 48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.38      0.52      0.44        63\n",
            "   Dependent       0.62      0.47      0.53       102\n",
            "\n",
            "    accuracy                           0.49       165\n",
            "   macro avg       0.50      0.50      0.49       165\n",
            "weighted avg       0.53      0.49      0.50       165\n",
            "\n",
            "[[33 37]\n",
            " [44 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.43      0.47      0.45        70\n",
            "   Dependent       0.57      0.53      0.55        94\n",
            "\n",
            "    accuracy                           0.51       164\n",
            "   macro avg       0.50      0.50      0.50       164\n",
            "weighted avg       0.51      0.51      0.51       164\n",
            "\n",
            "[[31 60]\n",
            " [28 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.53      0.34      0.41        91\n",
            "   Dependent       0.43      0.62      0.51        73\n",
            "\n",
            "    accuracy                           0.46       164\n",
            "   macro avg       0.48      0.48      0.46       164\n",
            "weighted avg       0.48      0.46      0.45       164\n",
            "\n",
            "[[27 12]\n",
            " [75 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.26      0.69      0.38        39\n",
            "   Dependent       0.81      0.40      0.53       125\n",
            "\n",
            "    accuracy                           0.47       164\n",
            "   macro avg       0.54      0.55      0.46       164\n",
            "weighted avg       0.68      0.47      0.50       164\n",
            "\n",
            "[[57 90]\n",
            " [ 6 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Independent       0.90      0.39      0.54       147\n",
            "   Dependent       0.11      0.65      0.19        17\n",
            "\n",
            "    accuracy                           0.41       164\n",
            "   macro avg       0.51      0.52      0.36       164\n",
            "weighted avg       0.82      0.41      0.51       164\n",
            "\n",
            "Mean precision score after 10-fold cross validation: 0.5681427177000911\n",
            "Mean recall score after 10-fold cross validation: 0.4871840354767184\n",
            "Mean F1 score after 10-fold cross validation: 0.5007641895952444\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "updated_features = pd.concat([features, new_features])\n",
        "\n",
        "#10-fold cross validator\n",
        "kf = KFold(n_splits = 10)\n",
        "\n",
        "#Create an SVM classifier\n",
        "svm = SVC(kernel='rbf', C=20.0, gamma='scale')\n",
        "\n",
        "#List the results of the 10-fold CV\n",
        "f1_scores = []\n",
        "prec_scores = []\n",
        "rec_scores = []\n",
        "\n",
        "updated_labels = labels + new_labels\n",
        "updated_labels = np.array(updated_labels)\n",
        "\n",
        "for k, (train, test) in enumerate(kf.split(updated_features, updated_labels)):\n",
        "    #Fit the SVC classifier\n",
        "    svm.fit(updated_features.iloc[train], updated_labels[train])\n",
        "    \n",
        "    #Predict y\n",
        "    y_predict = svm.predict(updated_features.iloc[test])\n",
        "\n",
        "    #Collect scores from all splits\n",
        "    prec_scores.append(precision_score(updated_labels[test], y_predict, average='weighted'))\n",
        "    rec_scores.append(recall_score(updated_labels[test], y_predict, average='weighted'))\n",
        "    f1_scores.append(f1_score(updated_labels[test], y_predict, average='weighted'))\n",
        "    \n",
        "    #Print confusion matrix and classification report\n",
        "    print(confusion_matrix(updated_labels[test], y_predict))\n",
        "    print(classification_report(updated_labels[test], y_predict, target_names=[\"Independent\", \"Dependent\"]))\n",
        "    \n",
        "#Print mean scores from all splits\n",
        "print(\"Mean precision score after 10-fold cross validation: {}\".format(np.mean(prec_scores)))\n",
        "print(\"Mean recall score after 10-fold cross validation: {}\".format(np.mean(rec_scores)))\n",
        "print(\"Mean F1 score after 10-fold cross validation: {}\".format(np.mean(f1_scores)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c18a2c407ccec57f8fa01186a1626f4778080785bc0bd4c998ef6d556cd9a626"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
